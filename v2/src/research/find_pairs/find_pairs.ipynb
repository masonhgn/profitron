{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee35dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e49650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sp500_tickers():\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    tables = pd.read_html(url)\n",
    "    sp500_table = tables[0]\n",
    "    return sp500_table['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9012417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_ohlcv_yfinance(ticker, period_days=180):\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=period_days)\n",
    "\n",
    "    df = yf.download(\n",
    "        ticker,\n",
    "        start=start.strftime('%Y-%m-%d'),\n",
    "        end=end.strftime('%Y-%m-%d'),\n",
    "        interval='1d',\n",
    "        auto_adjust=False,\n",
    "        progress=False\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2e080ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiple_ohlcv_yfinance(tickers, period_days=180, sleep_seconds=0.2):\n",
    "    end = datetime.today()\n",
    "    start = end - timedelta(days=period_days)\n",
    "\n",
    "    all_data = {}\n",
    "    \n",
    "    for ticker in tqdm(tickers, desc=\"Fetching OHLCV\"):\n",
    "        try:\n",
    "            df = yf.download(\n",
    "                ticker,\n",
    "                start=start.strftime('%Y-%m-%d'),\n",
    "                end=end.strftime('%Y-%m-%d'),\n",
    "                interval='1d',\n",
    "                auto_adjust=False,\n",
    "                progress=False\n",
    "            )\n",
    "            if not df.empty:\n",
    "                all_data[ticker] = df\n",
    "            else:\n",
    "                print(f\"⚠️ No data for {ticker}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Failed for {ticker}: {e}\")\n",
    "        sleep(sleep_seconds)\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1242d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching OHLCV:  12%|█▏        | 60/503 [00:21<02:50,  2.60it/s]ERROR:yfinance:\n",
      "1 Failed download:\n",
      "ERROR:yfinance:['BRK.B']: YFTzMissingError('possibly delisted; no timezone found')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data for BRK.B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching OHLCV:  15%|█▍        | 74/503 [00:27<02:42,  2.64it/s]ERROR:yfinance:\n",
      "1 Failed download:\n",
      "ERROR:yfinance:['BF.B']: YFPricesMissingError('possibly delisted; no price data found  (1d 2024-10-09 -> 2025-04-07)')\n",
      "Fetching OHLCV:  15%|█▍        | 75/503 [00:28<02:36,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No data for BF.B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching OHLCV: 100%|██████████| 503/503 [03:18<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price        Adj Close       Close        High         Low        Open  \\\n",
      "Ticker            AAPL        AAPL        AAPL        AAPL        AAPL   \n",
      "Date                                                                     \n",
      "2025-03-31  222.130005  222.130005  225.619995  216.229996  217.009995   \n",
      "2025-04-01  223.190002  223.190002  223.679993  218.899994  219.809998   \n",
      "2025-04-02  223.889999  223.889999  225.190002  221.020004  221.320007   \n",
      "2025-04-03  203.190002  203.190002  207.490005  201.250000  205.539993   \n",
      "2025-04-04  188.380005  188.380005  199.880005  187.339996  193.889999   \n",
      "\n",
      "Price          Volume  \n",
      "Ticker           AAPL  \n",
      "Date                   \n",
      "2025-03-31   65299300  \n",
      "2025-04-01   36412700  \n",
      "2025-04-02   35905900  \n",
      "2025-04-03  103419000  \n",
      "2025-04-04  125569000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tickers = get_sp500_tickers()\n",
    "data_dict = get_multiple_ohlcv_yfinance(tickers)\n",
    "print(data_dict['AAPL'].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffbca01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_price_matrix(data_dict, field=\"Adj Close\"):\n",
    "    price_df = pd.DataFrame()\n",
    "\n",
    "    for ticker, df in data_dict.items():\n",
    "        if field in df.columns:\n",
    "            s = df[field].copy()\n",
    "            s.name = ticker\n",
    "            price_df = pd.concat([price_df, s], axis=1)\n",
    "    \n",
    "    # Drop rows with too many missing values (e.g., early dates)\n",
    "    price_df = price_df.dropna(thresh=int(0.8 * price_df.shape[1]))\n",
    "    price_df = price_df.fillna(method=\"ffill\").dropna(axis=1)  # ffill and drop any remaining NaNs\n",
    "    return price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f505bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import coint\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def find_cointegrated_pairs(price_df, significance=0.05):\n",
    "    tickers = price_df.columns\n",
    "    pairs = []\n",
    "    scores = []\n",
    "    pvalues = []\n",
    "\n",
    "    combos = list(itertools.combinations(tickers, 2))\n",
    "\n",
    "    for i, (t1, t2) in enumerate(tqdm(combos, desc=\"Testing cointegration pairs\")):\n",
    "        series1 = price_df[t1]\n",
    "        series2 = price_df[t2]\n",
    "\n",
    "        try:\n",
    "            score, pvalue, _ = coint(series1, series2)\n",
    "            if pvalue < significance:\n",
    "                pairs.append((t1, t2))\n",
    "                scores.append(score)\n",
    "                pvalues.append(pvalue)\n",
    "        except Exception:\n",
    "            continue  # skip bad pairs\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'pair': pairs,\n",
    "        'coint_score': scores,\n",
    "        'pvalue': pvalues\n",
    "    }).sort_values(by='pvalue')\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1121fe0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_price_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_price_matrix\u001b[49m(data_dict)\n\u001b[1;32m      2\u001b[0m pairs \u001b[38;5;241m=\u001b[39m find_cointegrated_pairs(price_df\u001b[38;5;241m=\u001b[39mdata)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'build_price_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "data = build_price_matrix(data_dict)\n",
    "pairs = find_cointegrated_pairs(price_df=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1915e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sp500_historical_data.csv')\n",
    "pairs = pd.read_csv('sp500_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159479ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def plot_cointegrated_pair(price_df, ticker1, ticker2):\n",
    "    series1 = price_df[ticker1]\n",
    "    series2 = price_df[ticker2]\n",
    "\n",
    "    # Step 1: Normalize prices for comparison\n",
    "    norm1 = series1 / series1.iloc[0]\n",
    "    norm2 = series2 / series2.iloc[0]\n",
    "\n",
    "    # Step 2: OLS to estimate hedge ratio\n",
    "    X = sm.add_constant(series2)\n",
    "    model = sm.OLS(series1, X).fit()\n",
    "    hedge_ratio = model.params[1]\n",
    "    spread = series1 - hedge_ratio * series2\n",
    "    zscore = (spread - spread.mean()) / spread.std()\n",
    "\n",
    "    # Step 3: Plot normalized price series\n",
    "    fig, axs = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "    axs[0].plot(norm1, label=ticker1)\n",
    "    axs[0].plot(norm2, label=ticker2)\n",
    "    axs[0].set_title(f\"Normalized Prices: {ticker1} vs {ticker2}\")\n",
    "    axs[0].legend()\n",
    "\n",
    "    # Step 4: Plot z-score of spread\n",
    "    axs[1].plot(zscore, label='Z-Score', color='purple')\n",
    "    axs[1].axhline(0, color='black', linestyle='--')\n",
    "    axs[1].axhline(1, color='green', linestyle='--')\n",
    "    axs[1].axhline(-1, color='red', linestyle='--')\n",
    "    axs[1].set_title(\"Z-Score of Spread\")\n",
    "    axs[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "top_pair = pairs.iloc[0]['pair']\n",
    "for i in range(len(pairs)):\n",
    "    print(pairs.iloc[i])\n",
    "plot_cointegrated_pair(data, top_pair[0], top_pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df619ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('sp500_historical_data.csv')\n",
    "pairs.to_csv('sp500_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e881bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502\n"
     ]
    }
   ],
   "source": [
    "#print(len(data_dict.items()))\n",
    "print(len(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1306661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5655\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def test_cointegrated_pair(series1, series2, adf_thresh=0.01, max_zstd=1.25, min_cross=10):\n",
    "    X = sm.add_constant(series2)\n",
    "    model = sm.OLS(series1, X).fit()\n",
    "    hedge_ratio = model.params.iloc[1]\n",
    "    spread = series1 - hedge_ratio * series2\n",
    "    z = (spread - spread.mean()) / spread.std()\n",
    "\n",
    "    # ADF test on spread\n",
    "    adf_stat, adf_pval, *_ = adfuller(spread)\n",
    "    if adf_pval > adf_thresh:\n",
    "        return False\n",
    "\n",
    "    # Volatility filter\n",
    "    if z.std() > max_zstd or z.abs().max() > 4:\n",
    "        return False\n",
    "\n",
    "    # Zero crossings\n",
    "    crossings = ((z.shift(1) * z) < 0).sum()\n",
    "    if crossings < min_cross:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def calculate_half_life(spread):\n",
    "    spread_lag = spread.shift(1)\n",
    "    spread_lag.iloc[0] = spread_lag.iloc[1]\n",
    "    delta = spread - spread_lag\n",
    "\n",
    "    model = sm.OLS(delta, sm.add_constant(spread_lag)).fit()\n",
    "    lambda_ = model.params.iloc[1]\n",
    "    if lambda_ >= 0:\n",
    "        return np.inf\n",
    "    half_life = -np.log(2) / lambda_\n",
    "    return half_life\n",
    "\n",
    "\n",
    "\n",
    "def stable_cointegration(series1, series2, adf_thresh=0.01):\n",
    "    n = len(series1)\n",
    "    half = n // 2\n",
    "\n",
    "    s1a, s2a = series1[:half], series2[:half]\n",
    "    s1b, s2b = series1[half:], series2[half:]\n",
    "\n",
    "    def adf_test(s1, s2):\n",
    "        model = sm.OLS(s1, sm.add_constant(s2)).fit()\n",
    "        spread = s1 - model.params.iloc[1] * s2\n",
    "        return adfuller(spread)[1]  # p-value\n",
    "\n",
    "    return (adf_test(s1a, s2a) < adf_thresh) and (adf_test(s1b, s2b) < adf_thresh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filtered_pairs = []\n",
    "import ast\n",
    "print(len(pairs))\n",
    "for _, row in pairs.iterrows():\n",
    "    p = ast.literal_eval(row['pair'])\n",
    "    t1, t2 = p\n",
    "    series1 = data[t1]\n",
    "    series2 = data[t2]\n",
    "\n",
    "    # Step 1: Basic filters (ADF, z-score stats, crossings)\n",
    "    if not test_cointegrated_pair(series1, series2):\n",
    "        continue\n",
    "\n",
    "    # Step 2: Check for stable cointegration across time\n",
    "    if not stable_cointegration(series1, series2):\n",
    "        continue\n",
    "\n",
    "    # Step 3: Calculate spread and half-life\n",
    "    X = sm.add_constant(series2)\n",
    "    model = sm.OLS(series1, X).fit()\n",
    "    hedge_ratio = model.params.iloc[1]\n",
    "\n",
    "    spread = series1 - hedge_ratio * series2\n",
    "    half_life = calculate_half_life(spread)\n",
    "\n",
    "    # Step 4: Filter based on half-life (e.g., must revert in 2–20 days)\n",
    "    if half_life < 2 or half_life > 20:\n",
    "        continue\n",
    "\n",
    "    # Passed all filters\n",
    "    filtered_pairs.append((t1, t2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5e0cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('APO', 'CRM'), ('APH', 'CDNS'), ('AMD', 'BXP'), ('APH', 'PNR'), ('DPZ', 'VRSK'), ('NRG', 'WFC'), ('CRM', 'SYF'), ('AOS', 'AMD'), ('ENPH', 'WTW'), ('NDAQ', 'NTRS'), ('KEY', 'MTB'), ('K', 'VRSN'), ('ERIE', 'KHC'), ('D', 'NUE'), ('CNP', 'TGT'), ('KO', 'WST'), ('ADM', 'BALL'), ('ENPH', 'VRSK'), ('PAYX', 'SWKS'), ('AON', 'DGX'), ('DHR', 'KR'), ('HD', 'NCLH'), ('ETR', 'FOX'), ('PPL', 'RSG'), ('JKHY', 'VST'), ('AMD', 'IRM'), ('CVX', 'REG'), ('AIG', 'ANET'), ('ABNB', 'SPG'), ('BBY', 'CZR'), ('NSC', 'ORCL'), ('AMP', 'PNC'), ('PODD', 'JPM'), ('ALLE', 'ADM'), ('FSLR', 'K'), ('PH', 'TFC'), ('CPAY', 'TFC'), ('CSCO', 'FTNT'), ('CCL', 'CRM'), ('ETN', 'FDX'), ('FE', 'PHM'), ('MU', 'SWK'), ('BEN', 'TYL'), ('BBY', 'WDC'), ('ALLE', 'BXP'), ('D', 'PFG'), ('D', 'XOM'), ('FSLR', 'MLM'), ('D', 'ES'), ('D', 'LIN'), ('GLW', 'KEYS'), ('EW', 'GD'), ('CVS', 'DUK'), ('EXPD', 'SBAC'), ('DLR', 'TROW'), ('CVX', 'FITB'), ('FSLR', 'IRM'), ('DLR', 'PNR'), ('CVX', 'SYF'), ('CVX', 'CRM'), ('CVX', 'STT'), ('ETN', 'IEX'), ('CVX', 'WDAY'), ('FSLR', 'PWR'), ('MU', 'REGN'), ('D', 'UHS'), ('ENPH', 'KHC'), ('D', 'FCX'), ('ALLE', 'AVY'), ('CF', 'PWR'), ('PODD', 'RCL'), ('CVX', 'ERIE'), ('PEG', 'GWW'), ('SNA', 'URI'), ('EMN', 'EXR'), ('CVX', 'MTB'), ('ENPH', 'WST'), ('D', 'MHK'), ('AOS', 'NXPI'), ('FSLR', 'VMC'), ('CVX', 'HST'), ('D', 'PHM'), ('PKG', 'TT'), ('FE', 'NVR'), ('ERIE', 'O'), ('CAG', 'CRWD'), ('CVX', 'CMG'), ('FE', 'LHX'), ('CVX', 'FDS'), ('ABNB', 'ROK'), ('D', 'LEN'), ('TECH', 'MSFT'), ('D', 'MKTX'), ('APH', 'APO'), ('BAC', 'EMR'), ('ADSK', 'GPN'), ('ENPH', 'JKHY'), ('D', 'INTC'), ('D', 'GD'), ('CBOE', 'CI'), ('ALLE', 'FIS')]\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "print(filtered_pairs)\n",
    "print(len(filtered_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82f2d078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(filtered_pairs, columns=[\"asset_1\", \"asset_2\"])\n",
    "df[\"type_1\"] = \"equity\"\n",
    "df[\"type_2\"] = \"equity\"\n",
    "\n",
    "df.to_csv('pairs.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
